{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNJa5y5t7jTlK9DYM/u/nZy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarinaSupiot/projet_7/blob/main/MLFLOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gee1Y83O2pX",
        "outputId": "4fe690e8-10b0-48e8-9acc-6ef80762e505"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLnVFKacO-BF",
        "outputId": "9f345efd-8cc3-4e8a-c1a5-7391109efb68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.44.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (533 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/533.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/533.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m533.5/533.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.44.0 slicer-0.0.7\n",
            "Collecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.11.4)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.10/dist-packages (from scikit-plot) (1.3.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->scikit-plot) (1.16.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n",
            "Collecting kds\n",
            "  Downloading kds-0.1.3-py3-none-any.whl (7.4 kB)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from kds) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from kds) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from kds) (1.23.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.0->kds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.20.0->kds) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->kds) (1.16.0)\n",
            "Installing collected packages: kds\n",
            "Successfully installed kds-0.1.3\n",
            "Version des librairies utilisées :\n",
            "Matplotlib            : 3.7.1\n",
            "Missingno             : 0.5.2\n",
            "NumPy                 : 1.23.5\n",
            "Pandas                : 1.5.3\n",
            "Seaborn               : 0.12.2\n",
            "Shap                  : 0.44.0\n",
            "Sklearn               : 1.2.2\n"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "from hyperopt import hp\n",
        "from hyperopt import tpe\n",
        "from hyperopt import fmin\n",
        "from hyperopt import space_eval, STATUS_OK\n",
        "import plotly.express as px\n",
        "from plotly.offline import iplot\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "import lightgbm as lgb\n",
        "#!pip install lime\n",
        "#from lime import lime_tabular\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import random\n",
        "import re\n",
        "import seaborn as sns\n",
        "!pip install shap\n",
        "import shap\n",
        "\n",
        "\n",
        "import sklearn\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, fbeta_score\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "!pip install scikit-plot\n",
        "!pip install kds\n",
        "\n",
        "import scikitplot as skplt\n",
        "import kds\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "\n",
        "\n",
        "import time\n",
        "\n",
        "# Versions\n",
        "print('Version des librairies utilisées :')\n",
        "\n",
        "\n",
        "print('Matplotlib            : ' + mpl.__version__)\n",
        "print('Missingno             : ' + msno.__version__)\n",
        "print('NumPy                 : ' + np.version.full_version)\n",
        "print('Pandas                : ' + pd.__version__)\n",
        "print('Seaborn               : ' + sns.__version__)\n",
        "print('Shap                  : ' + shap.__version__)\n",
        "print('Sklearn               : ' + sklearn.__version__ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gouMXInAiJDH"
      },
      "outputs": [],
      "source": [
        "def cout_metier(y_true, y_pred, fn_value=-10, fp_value=-1, vp_value=0, vn_value=1):\n",
        "    mat_conf = confusion_matrix(y_true, y_pred)\n",
        "    vn = mat_conf[0, 0]\n",
        "    fn = mat_conf[1, 0]\n",
        "    fp = mat_conf[0, 1]\n",
        "    vp = mat_conf[1, 1]\n",
        "    J = vp * vp_value + vn * vn_value + fp * fp_value + fn * fn_value\n",
        "    # Coût maximum\n",
        "    max_J = (fp + vn)*vn_value + (fn + vp)*vp_value\n",
        "\n",
        "    # Coût minimum\n",
        "    min_J = (fp + vn)*fp_value + (fn + vp)*fn_value\n",
        "\n",
        "    # Coût normalisé entre 0 et 1\n",
        "    J_normalized = (J - min_J)/(max_J - min_J)\n",
        "\n",
        "    return J_normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Connexion MLFLOW"
      ],
      "metadata": {
        "id": "qHuPDNRIPpDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow\n",
        "import mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dgj3kBVaPoOx",
        "outputId": "a5c6945b-c79a-4473-b7b0-6cd6054f0501"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.9.1-py3-none-any.whl (19.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.8.0)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow)\n",
            "  Downloading alembic-1.13.0-py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker<7,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.23)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<15,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (9.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.1)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.2)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow) (1.6.4)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, Mako, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, mlflow\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.0 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.40 gunicorn-21.2.0 mlflow-2.9.1 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier"
      ],
      "metadata": {
        "id": "znqb1JZa46gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QBnRT7DHphQ8"
      },
      "outputs": [],
      "source": [
        "seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FFDcAO26tInH"
      },
      "outputs": [],
      "source": [
        "#chargement des train set et val set\n",
        "train_set = pickle.load( open( \"/content/drive/MyDrive/Projet 7/train_set.p\", \"rb\" ) )\n",
        "val_set = pickle.load( open( \"/content/drive/MyDrive/Projet 7/val_set.p\", \"rb\" ) )\n",
        "train_labels = pickle.load( open( \"/content/drive/MyDrive/Projet 7/train_labels.p\", \"rb\" ) )\n",
        "val_labels = pickle.load( open( \"/content/drive/MyDrive/Projet 7/val_labels.p\", \"rb\" ) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qWLbd8OukPtK"
      },
      "outputs": [],
      "source": [
        "train_sample_set = pickle.load( open( \"/content/drive/MyDrive/Projet 7/train_sample_set.p\", \"rb\" ) )\n",
        "val_sample_set = pickle.load( open( \"/content/drive/MyDrive/Projet 7/val_sample_set.p\", \"rb\" ) )\n",
        "train_sample_labels = pickle.load( open( \"/content/drive/MyDrive/Projet 7/train_sample_labels.p\", \"rb\" ) )\n",
        "val_sample_labels = pickle.load( open( \"/content/drive/MyDrive/Projet 7/val_sample_labels.p\", \"rb\" ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RebG25x7biBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AdaBoost"
      ],
      "metadata": {
        "id": "ShBJ1LCUbqfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition d'une expérience (Une expérience peut contenir plusieurs *runs*)\n",
        "mlflow.set_experiment(\"AdaBoost\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/Adaboost/model_smote.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='AdaBoost_Smote'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "id": "mj-y27ecLI0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010029f3-0163-4dd7-b2a1-93d5c51484b1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/12/07 13:22:15 INFO mlflow.tracking.fluent: Experiment with name 'AdaBoost' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5160987155312156\n",
            "0.03825136612021858\n",
            "0.3888888888888889\n",
            "0.06965174129353234\n",
            "0.6738653001464129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"AdaBoost\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/Adaboost/model_0.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='AdaBoost_wight'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDL_ZTi9dpmq",
        "outputId": "999d5d64-9dfe-4563-d045-557b680e8efa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.6650805270863837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"AdaBoost\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/Adaboost/model_us.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='AdaBoost_Undersampling'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ5psX64eKQN",
        "outputId": "92f9b9f5-b3ed-4ce7-d033-d05624ee659c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5013563461058431\n",
            "0.00546448087431694\n",
            "0.16666666666666666\n",
            "0.010582010582010581\n",
            "0.6650805270863837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"AdaBoost\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/Adaboost/model_su02.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='AdaBoost_SMOTE_02'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfQqHmeveiu7",
        "outputId": "be81a95f-586c-4148-c2f1-3601481f13f6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.6650805270863837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"AdaBoost\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/Adaboost/model_su04.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='AdaBoost_SMOTE_04'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdkRNqZSfBCv",
        "outputId": "c81a8264-1616-4e2c-94f4-0e6b3b6633a1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5\n",
            "0.0\n",
            "0.0\n",
            "0.0\n",
            "0.6650805270863837\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dummy Regressor"
      ],
      "metadata": {
        "id": "e0LXrDerc0B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Dummy\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/DummyRegressor/model_0.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='Dummy_poids'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpNFND--c3WS",
        "outputId": "5c0fcac8-7cf1-4ddc-f0de-6aa793c5fbd1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/12/07 13:25:35 INFO mlflow.tracking.fluent: Experiment with name 'Dummy' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49094014934844266\n",
            "0.07103825136612021\n",
            "0.07428571428571429\n",
            "0.07262569832402235\n",
            "0.6295754026354319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Dummy\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/DummyRegressor/model_smote.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='SMOTE'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tx4EpraddhZ",
        "outputId": "6b3425de-22b1-4b4d-d69b-6d34aab02acb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4990661963062877\n",
            "0.4918032786885246\n",
            "0.0911854103343465\n",
            "0.15384615384615385\n",
            "0.5014641288433382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Undersampling"
      ],
      "metadata": {
        "id": "-whd-w5mdv9P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Dummy\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/DummyRegressor/model_us.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='Undersampling'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTzbeU3HdzsC",
        "outputId": "8a129d64-7cfd-45ff-9acc-9c1255c3a342"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4990661963062877\n",
            "0.4918032786885246\n",
            "0.0911854103343465\n",
            "0.15384615384615385\n",
            "0.5014641288433382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Dummy\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/DummyRegressor/model_su04.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='Smote 0.4'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfE0jwe0d6Tu",
        "outputId": "529ce403-8c9a-4ddb-b9eb-193b31a5bb80"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4990661963062877\n",
            "0.4918032786885246\n",
            "0.0911854103343465\n",
            "0.15384615384615385\n",
            "0.5014641288433382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Light GBM"
      ],
      "metadata": {
        "id": "jLAK1cxxeR2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Light GBM\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/model_0.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='LightGBM_poids'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T6NLngGekxx",
        "outputId": "7aa3f531-1335-4908-9041-40e75cef1d9e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023/12/07 13:33:05 INFO mlflow.tracking.fluent: Experiment with name 'Light GBM' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6541888839767708\n",
            "0.5136612021857924\n",
            "0.2012847965738758\n",
            "0.28923076923076924\n",
            "0.7005856515373353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Light GBM\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/model_smote.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='SMOTE'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WOlpGm0fIyP",
        "outputId": "56e96b1a-fa80-4908-d549-ab545cae7cfc"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6633494831749928\n",
            "0.5683060109289617\n",
            "0.19152854511970535\n",
            "0.2865013774104683\n",
            "0.6947291361639825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Light GBM\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/model_us.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='Undersampling'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRpGXbNJfb7v",
        "outputId": "3d8ee306-f045-40a9-b302-a54441fb9764"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6313264824321602\n",
            "0.366120218579235\n",
            "0.2627450980392157\n",
            "0.3059360730593607\n",
            "0.718887262079063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlflow.set_experiment(\"Light GBM\")\n",
        "mlflow.sklearn.autolog()  # Ici on fait appel à l'API MLflow qui intègre les algos de Scikit-Learn.\n",
        "                          # C'est grâce à ce code qu'on enregistre toutes les métriques et métadonnées de cette expérience (Module MLflow Tracking)\n",
        "\n",
        "with open('/content/drive/MyDrive/Projet 7/model_su04.pkl', 'rb') as file:\n",
        "    model = pickle.load(file)\n",
        "with mlflow.start_run(run_name='SMOTE 0.4'):\n",
        "    #model = build_pipeline(algo_ml=model)\n",
        "    #model.fit(train_sample_set.drop(columns=['SK_ID_CURR']), train_sample_labels)\n",
        "\n",
        "    # Prédictions sur les données d'entraînement\n",
        "    #train_preds = model.predict(train_sample_set.drop(columns=['SK_ID_CURR']))\n",
        "    # Prédictions sur les données de validation\n",
        "    val_preds = model.predict(val_sample_set.drop(columns=['TARGET']))\n",
        "\n",
        "    # Calcul des métriques\n",
        "    roc_auc = roc_auc_score(val_sample_labels, val_preds)\n",
        "    recall = recall_score(val_sample_labels, val_preds)\n",
        "    precision = precision_score(val_sample_labels, val_preds)\n",
        "    f1 = f1_score(val_sample_labels, val_preds)\n",
        "    cout = cout_metier(val_sample_labels, val_preds)\n",
        "\n",
        "\n",
        "    # Enregistrement des métriques dans les logs MLflow\n",
        "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
        "    mlflow.log_metric(\"recall\", recall)\n",
        "    mlflow.log_metric(\"precision\", precision)\n",
        "    mlflow.log_metric(\"f1_score\", f1)\n",
        "    mlflow.log_metric(\"cout\", cout)\n",
        "\n",
        "    print(roc_auc)\n",
        "    print(recall)\n",
        "    print(precision)\n",
        "    print(f1)\n",
        "    print(cout)\n",
        "\n",
        "mlflow.end_run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcoWA9_1fxti",
        "outputId": "effe3379-23a9-4a8f-f964-6e539a025431"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6570594657018866\n",
            "0.5573770491803278\n",
            "0.1875\n",
            "0.28060522696011003\n",
            "0.6899707174231332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b-sMIaX-fING"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvXJeRK5X2a_",
        "outputId": "986482ff-c476-40cb-fd2b-ccc5536517d5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.3-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyngrok import ngrok\n",
        "# Terminate open tunnels if exist\n",
        "ngrok.kill()\n",
        "\n",
        "# Setting the authtoken (optional)\n",
        "# Get your authtoken from https://dashboard.ngrok.com/auth\n",
        "NGROK_AUTH_TOKEN = \"2YGm2G54kBEMvnAj43IFcf4QK1O_7kd3J9UnbA4TGcvw9W5Np\"\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
        "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
        "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPIyz81PULUv",
        "outputId": "5cf39c4e-a4fc-431d-c274-6ec91b7bd709"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLflow Tracking UI: https://aa58-34-90-174-74.ngrok-free.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mlflow ui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIulHWc1UOJi",
        "outputId": "1eaa47e1-09e9-4727-fe16-5e911bc638eb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-12-07 13:37:50 +0000] [7917] [INFO] Starting gunicorn 21.2.0\n",
            "[2023-12-07 13:37:50 +0000] [7917] [INFO] Listening at: http://127.0.0.1:5000 (7917)\n",
            "[2023-12-07 13:37:50 +0000] [7917] [INFO] Using worker: sync\n",
            "[2023-12-07 13:37:50 +0000] [7918] [INFO] Booting worker with pid: 7918\n",
            "[2023-12-07 13:37:50 +0000] [7919] [INFO] Booting worker with pid: 7919\n",
            "[2023-12-07 13:37:50 +0000] [7920] [INFO] Booting worker with pid: 7920\n",
            "[2023-12-07 13:37:50 +0000] [7921] [INFO] Booting worker with pid: 7921\n",
            "\n",
            "[2023-12-07 13:38:27 +0000] [7917] [INFO] Handling signal: int\n",
            "Aborted!\n",
            "[2023-12-07 13:38:27 +0000] [7920] [INFO] Worker exiting (pid: 7920)\n",
            "[2023-12-07 13:38:27 +0000] [7919] [INFO] Worker exiting (pid: 7919)\n",
            "[2023-12-07 13:38:27 +0000] [7921] [INFO] Worker exiting (pid: 7921)\n",
            "[2023-12-07 13:38:27 +0000] [7918] [INFO] Worker exiting (pid: 7918)\n",
            "[2023-12-07 13:38:28 +0000] [7917] [INFO] Shutting down: Master\n"
          ]
        }
      ]
    }
  ]
}